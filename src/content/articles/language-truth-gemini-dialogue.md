---
title: "關於語言、真實與矛盾：我與 Gemini Pro 2.5 的對話錄"
description: "語言的本質充滿著模糊與不透明，而 AI 的訓練資料正是這些人類語言。AI 並非克服了模糊，而是吞噬了海量的模糊性來進行預測。AI 的「不精準」與「無意圖的說謊」是其機率模型的結構性必然。面對這種結構性的不誠實，人類必須採用「功能性的信任」，保持懷疑與核實的能力，才能避免在 AI 的權威語氣中讓渡自身的主體性與判斷力。"
date: 2025-11-08
pillar: faith
tags: ["語言哲學", "Gemini", "AI幻覺", "批判思維", "人機對話"]
draft: false
readingTime: 5
---

我與 Gemini Pro 2.5 進行了一場關於「語言與 AI 本質」的深刻對話。人類的語言本質上是不透明且模糊的。而 AI，正是建立在這種模糊性與不確定性之上的產物。

## 擁抱模糊的機率精準

訓練 AI 的材料本質是含糊的。詞語天生需要依賴上下文。

Gemini Pro 回應：AI 不是「理解」，而是「預測」。AI 不是克服了模糊，而是「吞噬」了海量的模糊性，學到詞語之間的統計關係。當上下文稀少時，機率模型就會「猜」，從而產生幻覺。

AI 是透過「擁抱並計算含糊本身」，來實現上下文的關聯性。

## 結構性的不誠實

從機率的角度來看，AI 常常產出與事實不符的結果。但這並非人類定義的「說謊」。

說謊者有「意圖」，知道事實卻故意扭曲。AI 沒有意圖，只知道哪種回應在統計上「最像答案」。當遇到事實空白時，算法會強迫 AI 生成最像答案的句子來維持連貫性。從結果看，這是一種「無意的說謊」，也是 AI 的「結構性不誠實」。

## 功能性的信任與清醒

面對這樣的 AI，我們該如何信任？Gemini 提出了「功能性的信任」原則：信任但要核實，AI 是助理，人類必須是總編輯。信任廣度而非精度，信任創造性任務甚於事實性任務，信任模式而非知識。

多數人渴望消除不確定性，容易將 AI 當作「神」或尺度，從而外包了判斷力，讓渡了主體性。在人機互動中，能保持批判性思維與「後設認知」的對話，注定只屬於少數的清醒者。
