---
title: "六年倒数，走了一年：Schmidt 的超级智慧预言正在兑现吗？"
description: "2025 年 Eric Schmidt 说六年内 AI 将超越人类整体智慧。九个月后，AI 已经在写自己的程序代码、debug 自己的训练流程。预言走到哪了？哪些超速、哪些卡关？"
date: 2026-02-26
pillar: ai
cover: "/images/covers/ai-surpass-human-intelligence-six-years.jpg"
tags:
  - AI趋势
  - AGI
  - 递归自我优化
  - Eric Schmidt
  - 产业分析
lang: zh-TW
medium_original: true
---

去年五月，前 Google 执行长 Eric Schmidt 在一场公开对谈中丢出一个让全场安静的预测：六年内，AI 的智慧总量将超越全人类的总和。

当时我把它整理成一篇文章，觉得这是一个值得记录的历史时刻——不管你信不信，至少有一个曾经掌管全球最大科技平台的人，拿自己的信誉押了这个赌注。

九个月过去了。倒数计时少了一年，现在是「五年」。我想重新检视这个预言：哪些部分已经开始兑现、哪些在变形、哪些可能根本走不到？

## AI 程序员：不是预言，是现在进行式

Schmidt 当时说，「未来一年内，绝大多数人类程序设计师与高阶数学研究人员将被 AI 取代。」这个说法在 2025 年五月听起来很激进。到了 2026 年二月，它不再激进——它变成了硅谷的日常。

Anthropic 的 Claude Code 在 2025 年 11 月 24 日更新后，开发者在圣诞假期试用，震惊到给它取了个名字叫「Claude Christmas」。不是因为它写得比人快，而是因为它能独立完成原本需要好几周的专案。Anthropic 和 OpenAI 的工程师公开说，AI 现在写了他们 100% 的程序代码。微软说 30%，Google 说超过 25%。Meta 的 Zuckerberg 放话年中前要让 AI 写大部分的程序代码。

MIT Technology Review 把「生成式程序设计」列入 2026 年十大突破技术。SWE-bench（一个测试 AI 修 bug 能力的标准测试）从 2024 年八月的 33% 正确率，一年后飙到超过 70%。UC Berkeley 的计算机科学教授 James O'Brien 说了一句让人不舒服的话：「再过一年，我预期 AI 写程序会比任何人类都好。」

旧金山的工程师开始用「permanent underclass」（永久底层阶级）来形容自己的未来。这个词的出现，本身就是一种验证——Schmidt 的预言不再是远方的假设，而是现在式的焦虑。

## 递归自我优化：从理论边界走进实验室

Schmidt 当时提到一个更深层的趋势：AI 已经开始参与自己的升级。他引述的数据是「10% 到 20% 的研究程序代码由 AI 自行生成」。这个数字听起来温和，但它指向的方向一点都不温和——那就是递归式自我优化（Recursive Self-Improvement, RSI）。

2026 年 2 月，OpenAI 发布了 GPT-5.3-Codex。技术文件里有一句不起眼的话：「GPT-5.3-Codex 被用于 debug 自己的训练管线、管理部署基础设施、并诊断测试过程中的错误。」这是 AI 参与改进自身的明确纪录——虽然还在人类监督下，但方向已经确立。

学术界也在正式化这个领域。ICLR 2026（国际学习表征会议）设立了第一个 RSI 专题工作坊，从「哲学思想实验」正式升格为「主流科学议程」。Google DeepMind 的 Demis Hassabis 在 2026 年世界经济论坛上公开讨论：「自我优化回路能不能在没有人类介入的情况下闭合？」他承认，目前还缺少关键能力，但这个问题本身就说明了方向。

Dean W. Ball 在一篇广为流传的分析中写道：前沿 AI 实验室正在自动化大量的研究与工程运作，2026 年这个速度会继续加快。每家实验室的有效「劳动力」将从几千人膨胀到数万、甚至数十万——而这些「员工」不需要睡觉、吃饭，也不用上厕所。他们唯一的目标，就是让自己变得更聪明。

这不是科幻。这是正在发生的工程事实。

## AGI 时间表：共识在，定义没有

Schmidt 当时提出的「旧金山共识」——AGI 将在三到五年内实现——到了 2026 年，这个共识依然存在，甚至更强了。Hassabis 说三到五年，Amodei 的 Anthropic 已经在内部设定类似的里程碑，OpenAI 的 Pachocki 给出了更具体的时间：2026 年九月做出「研究实习生」等级的 AI。

但问题来了：每个人说「AGI」的时候，讲的是同一件事吗？

Schmidt 的定义是「像最优秀的艺术家、作家、政治家那样进行综合性思考与创造」。OpenAI 的操作定义偏向「能取代知识工作者」。Hassabis 在意的是「发明新假说的能力」——像爱因斯坦提出相对论那样，不只是证明现有猜想，而是提出全新的。

这些定义之间的距离，可能比 AGI 离我们的距离还远。目前 AI 做得到的是：在既定框架内高效执行、在大量数据中找到模式、在明确指令下完成复杂任务。做不到的是：在没有人类提问的情况下自己发现值得问的问题。

这个差距不是靠 scaling 就能跨过的。它涉及的不只是计算量，而是我们还没完全理解的「理解」本身。

## 超级智慧：六年变五年，距离有没有缩短？

Schmidt 最大胆的预言是 ASI——人工超级智慧——六年内出现。现在过了一年，倒数到五年。

从硬件面看，速度超过预期。Blackwell 世代的芯片开始部署，每家实验室都在扩建 GW 等级的数据中心。Rubin 世代也即将进入实战。运算力的供给面正在指数级扩张。

从软件面看，RSI 的早期迹象确实出现了。AI 开始参与自身的训练、debug、甚至架构设计。从 2025 年底到 2026 年初，OpenAI 模型迭代的间隔从六个月缩短到不到两个月，这个加速本身就是 RSI 效应的间接证据。

但「超越全人类智慧总和」？这需要的不只是速度，而是质的跳跃。目前的 AI——不管多快、多准——本质上仍然是在人类设定的目标函数里优化。它没有自己的好奇心，没有自己的问题意识，没有在失败中产生的直觉。

我的判断是：五年内，我们会看到在特定领域超越所有人类的 AI 系统。但「超越全人类整体智慧」这个宣称，混淆了「能力」和「智慧」。能力可以堆叠，智慧涉及判断、伦理、意义——这些不是规模问题。

## 台湾站在哪里

每次讨论这种全球级的技术趋势，我都会问一个问题：台湾在这个局里的位置是什么？

答案很矛盾。台湾握着全世界最关键的硬件——台积电的先进制程是所有 AI 芯片的命脉。但在 AI 应用、AI 研究、AI 人才、AI 能源这四个维度上，台湾都不是主角。

我们是「武器供应商」，不是「参战方」。这个角色在和平时期很赚钱，但在技术典范转移的时刻，只做供应商是危险的——因为你的价值取决于别人的需求，而不是你自己的能力。

Schmidt 预测的那个世界——AI 自我优化、不需要人类接口——如果真的到来，对台湾最大的冲击不是芯片需求消失，而是我们在 AI 价值链的位置被固定在最底层的硬件代工。

## 倒数五年的清醒笔记

回到 Schmidt 的预言。九个月前我纪录他的话，心态是「这值得记下来」。现在重看，心态变了——变成「他可能低估了某些面向，也高估了某些面向」。

低估的是 AI 在程序设计上的进展速度。Claude Code Christmas 和 100% AI-written code 的现实，比大多数人预期的都快。

高估的是「不需要人类」这个叙事。AI 确实越来越能自主完成任务，但它越能干，人类对「可靠性」和「可控性」的要求就越高。矛盾在这里：AI 能力的进步速度，超过了人类信任的建立速度。

六年倒数走了一年。技术面，速度超预期。但文明面——法律、伦理、教育、治理——Schmidt 说的「我们连描述这个变化的语言都还没有」，到今天依然成立。

这不只是科技问题。这是我们这个世代必须回答的文明命题：当机器开始改进自己，人类的角色是什么？

不是「我们会不会被取代」这种问题。而是更根本的：在一个智慧可以被大量复制的世界里，「人」的定义是什么？

这个问题，没有任何 AI 能帮我们回答。