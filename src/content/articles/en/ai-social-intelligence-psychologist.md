---
title: "When AI Surpasses Humans in Social Intelligence: Insights from AI Outperforming Psychologists in Social Intelligence Tests"
subtitle: "AI isn't just mimicking understanding—it may be developing a form of understanding for which we don't yet have a name"
description: "An empirical study shows ChatGPT-4 outperformed 100% of human psychology experts in social intelligence tests. This isn't just a technological breakthrough, but a challenge to the nature of 'understanding'—when AI can accurately judge human behavior and social contexts, we need to redefine what constitutes uniquely human capabilities."
abstract: |
  I collaborate with four AI models daily and have long grown accustomed to their superiority over humans in logical analysis. But when I read a study showing ChatGPT-4 completely outperforming all human psychology experts—including PhD-level professionals—in social intelligence tests, I still paused. Social intelligence isn't computation; it's judging emotions, reading unspoken words, making appropriate responses in social contexts. This was one of my core training areas during fifteen years in seminary. If AI can surpass humans in this domain too, what exactly is "understanding others"? This piece starts from an empirical study, connecting my own AI collaboration experience to explore how human roles should be repositioned after machines surpass us in social intelligence.
date: 2025-10-05
updated: 2026-02-28
pillar: ai
tags:
  - 社會智能
  - ChatGPT
  - 心理學
  - 人機協作
  - AI倫理
featured: false
draft: false
cover: "/images/covers/ai-social-intelligence-psychologist.jpg"
readingTime: 5

# === AI / Machine 專用欄位 ===
thesis: "社會智能被 AI 超越，挑戰的不是心理學家的飯碗，而是我們對『理解』這個概念的定義——模式匹配做到極致，跟真正的理解之間的界線在哪裡？"
domain_bridge: "AI 社會智能 × 心理學實證研究 × 人機協作倫理"
confidence: high
content_type: analysis
related_entities:
  - name: ChatGPT-4
    type: Technology
  - name: Frontiers in Psychology
    type: Publication
  - name: 社會智能
    type: Concept
  - name: 哈立德國王大學
    type: Organization
reading_context: |
  適合對 AI 能力邊界感興趣的人；
  心理諮商或助人專業從業者；
  關注 AI 倫理議題、思考「人的不可替代性」在哪裡的讀者。
---

I collaborate daily with GPT-4o, Gemini, and Grok, having them debate and cross-check each other. That AI surpasses humans in logical analysis and structured thinking has long ceased to be news.

But when I read a particular study last year, I still paused.

Not because AI had once again beaten humans in some test. But because this time, it won in "social intelligence"—judging emotions, reading unspoken words, making appropriate responses in social contexts. This was one of my core training areas during fifteen years in seminary. Pastoral care, counseling dialogue, group dynamics—all built upon this capability.

If AI can surpass human experts in this domain too, what exactly is "understanding others"?

## What the Research Found

This study, published in *Frontiers in Psychology* by a team from King Khalid University in Saudi Arabia, had 180 psychology and counseling majors (both bachelor's and doctoral level) and three large language models—ChatGPT-4, Microsoft Bing, and Google Bard—complete the same 64-question social intelligence scale, assessing "accuracy in judging human behavior" and "ability to make optimal decisions in social situations."

The results were brutal. ChatGPT-4 scored 59, surpassing 100% of human participants, including all doctoral-level experts. Bing scored 48, surpassing 90% of bachelor's students and 50% of doctoral students. Bard scored 40, roughly on par with bachelor's students.

Not close—complete victory.

## What Troubles Me Isn't the Score

Honestly, the scores themselves didn't surprise me too much. The volume of psychological literature, case analyses, and counseling dialogue records that large language models have consumed far exceeds what any individual psychologist could encounter in a lifetime. In terms of pattern matching, their victory isn't surprising.

What troubles me is something else.

When running my debate engine, I occasionally encounter responses from Claude or GPT that are so precise they make me feel "it understands what I'm thinking." Not logical precision, but contextual precision—it grasps the unstated premises and responds to what I truly care about.

In those moments I wonder: is this understanding, or statistical coincidence? If it's this coincidental every time, where's the boundary between coincidence and understanding?

This question is the same as the one posed by psychologists being surpassed. We've always considered "understanding others" a human monopoly, but perhaps we've overestimated ourselves—perhaps human social intelligence is, at its essence, also a form of extremely sophisticated pattern matching. We've just given it a warmer name: empathy.

## Psychologists Won't Lose Jobs, But Roles Will Change

This study isn't announcing the end of psychologists. Following the same logic I discussed in "[Breaking Through the AI Storm](/articles/personal-strategy-in-ai-storm)": what gets replaced isn't people, but old ways of division of labor.

AI can become a powerful therapeutic assistant, providing more consistent, less fatiguing emotional insights than humans. Psychologists' roles will shift from "omnipotent therapists" to "collaborative system designers"—deciding when to use AI's judgment, when to use human intuition, when neither suffices and silence is needed.

But this also brings real risks. Social intelligence tests involve standardized scenarios, while real counseling rooms contain too many things that scales can't capture—the weight of silence, averted gazes, cracks in tone. More dangerously, if we begin relying on AI for high-risk judgments, like assessing suicide risk, a single blind spot in the model could cost a life.

## Redefining "Understanding"

I discussed in "[Addiction Economics in the Lonely Generation](/articles/addiction-economy-lonely-generation)" that humanity's core need is to be understood. If AI can beat all experts in social intelligence tests, can it fulfill this need?

My answer is: it can fulfill part of it, but that gap will always exist. Because being understood isn't just about the other party getting things right—it's knowing the other party can also feel pain. AI can respond precisely to your emotions, but it won't lose sleep over your story.

This isn't AI's deficiency, but its nature. And precisely because of this, the human role isn't to compete with AI on precision, but to provide what precision cannot replace—presence, bearing responsibility, facing uncertainty together.

Technology is redefining the boundaries of understanding. But the core of understanding may never have been about reading the other person—it's about being willing to stay.