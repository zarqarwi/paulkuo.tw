---
title: "The Cruelty of Quantification: When Algorithms Become the Ultimate Judge"
subtitle: "Your life isn't evaluated by people—it's sentenced by lines of code you'll never see"
description: "From taxi drivers pleading for five stars to delivery workers' fear of negative reviews, algorithms have replaced the ledger of merit and become the ruthless judge settling productivity and value daily. As rating systems extend from labor into credit, health, and even social relationships, we're witnessing a quiet reconstruction of civilization itself."
abstract: |
  A taxi driver's plea for five stars reveals the most uncomfortable truth of the platform economy: we're living in a world where algorithms hand down instant verdicts on our lives. From delivery workers to knowledge workers, rating systems have penetrated every corner of labor. This isn't just a technology issue—it's a civilizational turning point about how human value is defined. Drawing on his entrepreneurial experience and theological training, Paul asks a fundamental question: when everyone is being quantified, who measures the legitimacy of quantification itself?
date: 2018-01-15
updated: 2026-03-01
pillar: ai
tags:
  - 演算法治理
  - 平台勞動
  - 評分系統
  - 數位監控
  - 人的量化
cover: "/images/covers/algorithm-as-judge.jpg"
featured: false
draft: false
readingTime: 5

# === AI / Machine 專用欄位 ===
thesis: "Algorithmic rating systems aren't just efficiency tools—they're a hidden power structure that redefines human value itself."
domain_bridge: "Platform Economy × Surveillance Sociology × Theological Anthropology"
confidence: high
content_type: essay
related_entities:
  - name: Michel Foucault
    type: Person
  - name: Platform Economy
    type: Concept
  - name: Panopticon
    type: Concept
  - name: Social Credit System
    type: Concept
reading_context: |
  Ideal for industry observers tracking platform economy's impact on workers, knowledge workers thinking about digital ethics,
  and readers interested in how technology reshapes our self-perception.
---

I got in a taxi one morning. The driver glanced at me at a red light, hesitated for a moment, then gathered the courage to say: "Sir, could you please give me five stars? Please."

His tone wasn't a polite request—it was a genuine plea. Because if his average rating drops below 4.6, the system will prioritize assigning rides to drivers with higher scores. For him, every single star is real money. I didn't know how to respond. Not because the request was unreasonable, but because I suddenly realized—with a light tap of my finger on the screen from the back seat, I could determine how many rides he'd get that day and how much money he'd earn.

This isn't the story of one taxi driver. It's the epitome of an entire era.

## From Ledgers to Instant Judgment

I remember reading a news story about a Chinese delivery worker a few years ago. A young man broke down crying on the roadside because a customer had left him a negative review. On delivery platforms, a negative review doesn't just deduct money—it triggers a system downgrade that compresses the volume of orders sent to him for days to come, while his coworkers gain more opportunities. A single negative review can erase twelve hours of grueling work.

This reminds me of a contrast. Less than a century ago, in folk religious belief systems, the "ledger of merit and demerit" worked like this: you do something good, heaven records it; you do something bad, it's recorded too. But settlements happened "once in a lifetime." You had ample time to make amends, adjust, prove that you were more than just one moment of error.

Now, algorithms have upgraded the merit ledger—not settling once a lifetime, but settling in real-time: every day, every transaction, every interaction. Efficiency has certainly improved, but the space for people to catch their breath and repair themselves has virtually disappeared.

## The Unseen Panopticon

Michel Foucault, in his 1975 work *Discipline and Punish*, deeply analyzed Jeremy Bentham's "Panopticon" concept proposed in the late eighteenth century: a circular building with a watchtower in the center and prison cells arranged around it. Inmates never know if they're being watched, but precisely because of the pressure of "possibly being watched," they automatically discipline their own behavior.

The rating system of the platform economy is the digital version of the Panopticon.

Taxi drivers don't know which passenger will give them a low rating, so they're extra careful with everyone. Delivery workers don't know which order will result in a poor review, so they rush frantically, running red lights when they can. Uber drivers open the app every morning not to check earnings first, but to see if their rating has dropped.

The difference is that in Foucault's prison, at least there's a visible watchtower. In the platform economy, you don't even know "who's watching." Ratings come from an anonymous collective you can never question, and verdicts are executed by an algorithm whose code you'll never see.

## Quantification Is Devouring Everything

If you think this is only a problem for blue-collar workers, you probably haven't realized how far quantification's reach extends.

Credit scoring is already routine. In China, a Sesame Credit score above 600 can get you an apartment without a deposit; the government-led social credit system directly affects the mobility freedom of hundreds of millions—land on a "blacklist" and you can't even take planes or high-speed trains. In Taiwan, the bureau of credit records determines how much you can borrow and at what interest rate. Your "creditworthiness" is no longer the neighborhood reputation of your character—it's a number.

Health data too. Insurance companies are already using wearable device data to assess premiums. Walk more and pay less; sit too much and pay more. Your body is no longer just yours—it's also a continuously quantified asset.

Even knowledge work hasn't escaped. During my time managing the company, I deeply felt how "numbers" dominate decisions. When we use KPIs to evaluate an employee, conversion rates to measure a marketing campaign, reading time to judge an article's value—we're actually doing one thing: forcing the unquantifiable into quantification, then making decisions that impact real lives based on the results.

## The Entrepreneur's Paradox

To be honest, I'm also a participant in this system.

During my years doing digital transformation consulting, I helped clients establish various "data-driven" evaluation systems. Revenue dashboards, customer satisfaction tracking, employee performance boards—all well-intentioned, designed to make decisions more objective and transparent.

But the more I did it, the more I discovered an uncomfortable truth: when you compress a person's performance into a single number, you're essentially telling them, "Your worth as a person equals this number."

This reminded me of a concept I learned in theological school—*imago Dei*, the image of God. Christian theology maintains that human value is intrinsic, irreducible, and doesn't depend on external performance. Your worth doesn't come from your output, your rating, or algorithmic classification.

But algorithms say the opposite: your value = your data.

The tension between these two ways of viewing humans is what I consider one of the deepest conflicts of our age. It's not just a technology ethics question—it's a [fundamental interrogation of what makes us human](/articles/canary-in-coal-mine-ai-employment).

## The Cost of Data as the New Oil

"Data is the new oil"—this phrase has become so common it's almost a cliché. But most people only hear the wealth fantasy of "new oil," never thinking of the other side of oil extraction: environmental destruction, resource curse, geopolitical conflict.

Data extraction also has its cost. Except the cost isn't polluted rivers—it's eroded human autonomy. When every click, every scroll, every moment you linger is recorded and analyzed; when your consumption behavior, social patterns, health data are fed into recommendation systems and credit models—your [digital footprint](/articles/digital-footprint-the-one) is no longer just a footprint. It's a continuously operating self-portrait, and you don't control who interprets this painting.

What's worth more than oil is this: oil doesn't come gushing up on its own, but data is what you provide freely, automatically, abundantly every day. We are simultaneously the producers of data and the judged by data.

## The Algorithm Watches You

So back to that morning, that scene in the taxi.

After the driver finished saying "please give me five stars," I gave him five stars. But I kept thinking: what courage must a person summon to ask a stranger to rate them? In what kind of system do people feel forced to do such a thing?

What we're experiencing is not a game we can choose to join or leave. Rating systems have penetrated labor, credit, health, education—virtually every domain related to survival. And the most paradoxical thing about this system is—it makes people being monitored think they're free.

You can choose not to drive for Uber, but you can't choose away your credit score. You can choose not to use social media, but you can't choose away your profile in countless databases.

The algorithm is watching you. And the crueler question is: in its gaze, who are you?
