---
title: "Six-Year Countdown, One Year Gone: Is Schmidt's Superintelligence Prophecy Coming True?"
description: "In 2025, Eric Schmidt predicted AI would surpass human collective intelligence within six years. Nine months later, AI is already writing its own code and debugging its own training processes. How far has the prophecy progressed? What's accelerating, and what's stalling?"
date: 2026-02-26
pillar: ai
tags:
  - AI Trends
  - AGI
  - Recursive Self-Improvement
  - Eric Schmidt
  - Industry Analysis
cover: "/images/covers/ai-surpass-human-intelligence-six-years.jpg"
featured: false
draft: false
readingTime: 7
thesis: "Schmidt's superintelligence prophecy is materializing ahead of schedule in programming, but overestimates progress in AGI definition and civilizational adaptation—capabilities can be stacked, but intelligence involves judgment and meaning, which isn't a scaling problem."
abstract: "Revisiting Eric Schmidt's six-year countdown prophecy from 2025: AI programming has shifted from prediction to reality (100% AI-written code), recursive self-improvement has moved from philosophy to laboratory, but surpassing all human intelligence conflates the essential difference between capability and intelligence. Taiwan's role as hardware supplier harbors hidden risks amid technological paradigm shift."
domain_bridge: "Starting from Schmidt's prophecy, connecting current AI programming status, recursive self-improvement engineering progress, AGI definitional divergences, and grounding in Taiwan's structural position in the AI value chain."
content_type: analysis
---

Last May, former Google CEO Eric Schmidt dropped a prediction in a public conversation that silenced the room: within six years, AI's total intelligence would surpass that of all humanity combined.

At the time, I summarized it in an article, thinking it was a historical moment worth recording—whether you believed it or not, at least someone who once controlled the world's largest tech platform was staking his credibility on this bet.

Nine months have passed. The countdown is now one year shorter—it's "five years." I want to revisit this prophecy: which parts are already materializing, which are transforming, and which might never come to pass?

## AI Programmers: Not Prophecy, Present Tense

Schmidt said back then, "Within the next year, the vast majority of human programmers and advanced mathematics researchers will be replaced by AI." This sounded radical in May 2025. By February 2026, it's no longer radical—it's become Silicon Valley's daily routine.

Anthropic's Claude Code, powered by the Opus 4.5 model released on November 24, 2025, shocked developers during Christmas break trials so much they nicknamed it "Claude Christmas." Not because it wrote faster than humans, but because it could independently complete projects that previously took weeks. Engineers at Anthropic and OpenAI publicly stated that AI now writes 100% of their code. Microsoft says 30%, Google says over 25%. Meta's Zuckerberg announced plans for AI to write most code by mid-year.

MIT Technology Review included "Generative Programming" in its 2026 breakthrough technologies list. SWE-bench (a standard test measuring AI's bug-fixing ability) jumped from 33% accuracy in August 2024 to over 70% a year later. UC Berkeley computer science professor James O'Brien made an uncomfortable statement: "In another year, I expect AI will program better than any human."

San Francisco engineers have started using "permanent underclass" to describe their future. The emergence of this term is itself a validation—Schmidt's prophecy is no longer a distant hypothesis, but present-tense anxiety.

## Recursive Self-Improvement: From Theoretical Boundaries to Laboratory

Schmidt mentioned a deeper trend: AI had already begun participating in its own upgrades. His cited data was "10% to 20% of research code generated by AI itself." This number sounds modest, but the direction it points toward is anything but—namely, Recursive Self-Improvement (RSI).

In February 2026, OpenAI released GPT-5.3-Codex. The technical documentation contained an unremarkable sentence: "GPT-5.3-Codex was used to debug its own training pipeline, manage deployment infrastructure, and diagnose errors during testing." This is explicit documentation of AI participating in self-improvement—though still under human supervision, the direction is established.

Academia is also formalizing this field. ICLR 2026 (International Conference on Learning Representations) established its first RSI workshop, officially elevating it from "philosophical thought experiment" to "mainstream scientific agenda." Google DeepMind's Demis Hassabis publicly discussed at the 2026 World Economic Forum: "Can self-optimization loops close without human intervention?" He acknowledged key capabilities are still missing, but asking the question itself reveals the direction.

Dean W. Ball wrote in a widely circulated analysis: frontier AI labs are automating vast amounts of research and engineering operations, and this pace will continue accelerating in 2026. Each lab's effective "workforce" will expand from thousands to tens of thousands, even hundreds of thousands—and these "employees" don't need sleep, food, or bathroom breaks. Their sole objective is making themselves smarter.

This isn't science fiction. This is ongoing engineering reality.

## AGI Timeline: Consensus Exists, Definition Doesn't

Schmidt's "San Francisco consensus"—that AGI would arrive within three to five years—by 2026, this consensus not only persists but has strengthened. Hassabis says three to five years, Amodei's Anthropic has internally set similar milestones, and OpenAI's Pachocki gave a more specific timeline: creating "research intern" level AI by September 2026.

But here's the problem: when everyone says "AGI," are they talking about the same thing?

Schmidt's definition is "synthetic thinking and creation like the best artists, writers, politicians." OpenAI's operational definition leans toward "can replace knowledge workers." Hassabis cares about "the ability to invent new hypotheses"—like Einstein proposing relativity, not just proving existing conjectures but proposing entirely new ones.

The distance between these definitions might be greater than AGI's distance from us. What current AI can do: efficiently execute within established frameworks, find patterns in massive data, complete complex tasks under clear instructions. What it cannot do: discover questions worth asking without human prompting.

This gap can't be crossed through scaling alone. It involves not just computational power, but "understanding" itself—which we don't fully comprehend.

## Superintelligence: Six Years to Five, Has Distance Shortened?

Schmidt's boldest prophecy was ASI—Artificial Superintelligence—appearing within six years. Now, one year later, the countdown is five years.

From hardware perspective, speed exceeds expectations. Blackwell generation chips are beginning deployment, every lab is expanding GW-scale data centers. The Rubin generation is also entering combat readiness. Computing power supply is expanding exponentially.

From software perspective, early signs of RSI are indeed appearing. AI is beginning to participate in its own training, debugging, even architectural design. From late 2025 to early 2026, OpenAI model iteration intervals shortened from six months to under two months—this acceleration itself is indirect evidence of RSI effects.

But "surpassing the sum of all human intelligence"? This requires not just speed, but qualitative leaps. Current AI—no matter how fast or accurate—essentially still optimizes within human-set objective functions. It has no curiosity of its own, no problem consciousness of its own, no intuition born from failure.

My judgment: within five years, we'll see AI systems that surpass all humans in specific domains. But the claim of "surpassing all human collective intelligence" confuses "capability" with "intelligence." Capabilities can be stacked; intelligence involves judgment, ethics, meaning—these aren't scaling problems.

## Where Taiwan Stands

Every time I discuss global-scale technological trends, I ask: what is Taiwan's position in this game?

The answer is contradictory. Taiwan holds the world's most critical hardware—TSMC's advanced processes are the lifeline for all AI chips. But across four dimensions—AI applications, AI research, AI talent, AI energy—Taiwan isn't the protagonist.

We're the "weapons supplier," not the "combatant." This role is profitable in peacetime, but during technological paradigm shifts, being only a supplier is dangerous—because your value depends on others' needs, not your own capabilities.

The world Schmidt predicts—AI self-optimization, no human interface needed—if it truly arrives, the biggest impact on Taiwan wouldn't be disappearing chip demand, but our position in the AI value chain being fixed at the lowest level of hardware manufacturing.

## Five-Year Countdown Sober Notes

Back to Schmidt's prophecy. Nine months ago I recorded his words with the mindset of "this is worth noting down." Now, rereading, my mindset has changed—to "he may have underestimated some aspects while overestimating others."

Underestimated: AI's progress speed in programming. The reality of Claude Code Christmas and 100% AI-written code came faster than most expected.

Overestimated: the "no humans needed" narrative. While AI increasingly can autonomously complete tasks, the more capable it becomes, the higher human demands for "reliability" and "controllability." The paradox: AI capability advancement speed exceeds human trust-building speed.

Six-year countdown, one year gone. Technically, speed exceeds expectations. But civilizationally—law, ethics, education, governance—Schmidt's observation that "we don't even have language to describe this change" remains true today.

This isn't just a technology problem. This is a civilizational proposition our generation must answer: when machines begin improving themselves, what is humanity's role?

Not questions like "will we be replaced." But more fundamentally: in a world where intelligence can be mass-replicated, what is the definition of "human"?

No AI can help us answer this question.