---
title: "The 2028 Slaughterhouse: An AI Collapse Scenario That Cost Wall Street Sleep"
description: "Citrini Research uses a five-ring chain analysis to predict systemic financial crisis triggered by AI, with Wall Street turmoil just the beginning."
pillar: ai
tags:
  - AI Economic Impact
  - Financial Crisis
  - White-Collar Unemployment
  - Narrative Economics
  - Citrini Research
date: 2026-02-27
cover: /images/covers/ai-slaughterhouse-2028-crisis-scenario.jpg
abstract: |
  Citrini Research's "2028 Global Intelligence Crisis" report uses a five-ring chain reaction to trace a path: AI creates phantom GDP, destroys intermediary business models, triggers white-collar unemployment waves, sparks private credit defaults, ultimately forming a negative feedback loop with no natural braking mechanism. This isn't prediction—it's a thought experiment. But the market reaction on February 23, 2026 proves that stories themselves are weapons.
thesis: "The real risk of AI collapse isn't at the technical layer, but at the narrative layer—markets only accept one story at a time, and fear always spreads faster than reason."
domain_bridge: "AI Systemic Risk × Narrative Economics"
confidence: speculative
content_type: analysis
related_entities:
  - name: Citrini Research
    type: Organization
  - name: James Van Gillen
    type: Person
  - name: Robert Shiller
    type: Person
  - name: Nassim Taleb
    type: Person
reading_context: |
  Suitable for investors and industry strategists concerned with AI's macroeconomic impact, as well as readers interested in narrative economics.
---

February 23, 2026, Wall Street endured an unusual Monday. IBM posted its largest single-day decline since 2025, American Express and Blackstone fell over 6%, and the software sector dropped nearly 5% overall. What triggered this volatility wasn't a Federal Reserve rate decision or some giant's earnings blowup, but a report from Citrini Research—a small investment research firm most people had never heard of.

The report's title was blunt to the point of provocation: "The 2028 Global Intelligence Crisis: A Financial History Thought Experiment from the Future." In Chinese circles, it was more directly translated as "The 2028 AI Slaughterhouse."

That's what makes this unsettling. Not Goldman Sachs, not Morgan Stanley, but a small firm with virtually no brand moat moved markets with a thought experiment. This suggests the market's nerves aren't just taut—they're already inflamed, where any stimulus could trigger spasms. Fear doesn't need authoritative endorsement; it just needs a complete enough storyline.

Citrini's storyline is a five-ring chain, each link connecting to the next, forming a path from prosperity to collapse.

The first ring they call "phantom GDP." The logic goes like this: AI enables corporate layoffs, profits soar, productivity hits new highs since the 1950s, and the numbers look gorgeous on paper—the S&P 500 approaching 8,000, NASDAQ breaking 30,000. But AI only produces; it doesn't consume. It won't buy houses, eat at restaurants, or take kids to Disney. Output increases, but labor compensation doesn't flow back to the consumption side. Money's velocity slows, the consumer economy atrophies. The GDP numbers are real, but the circulatory system supporting them is already stagnating.

The second ring is systematic collapse of business models. Once AI agents become consumers' omnipotent assistants, all intermediary layers surviving on "human inertia"—price comparison platforms, insurance renewals, travel booking, real estate brokerage—get pierced through. More lethal is the payment network: when transactions become machine-to-machine, credit cards' 2-3% transaction fees become pure redundant costs. AI agents will automatically switch to zero-cost stablecoin settlement, and Visa and Mastercard's moat is built precisely on this fee layer.

The third ring is white-collar unemployment triggering consumption collapse. America's structural weakness is exposed here: white-collar workers comprise half the workforce but contribute roughly 75% of discretionary consumption. After AI replaces white-collar workers, high-skill labor floods the gig economy—engineers driving rideshare, programmers becoming plumbers—depressing everyone's wages. Remaining white-collar workers begin precautionary saving, afraid to spend. The consumption engine stalls simultaneously from both supply and demand sides.

The fourth ring is financial system transmission. Of the $2.5 trillion in private credit, large amounts flow to SaaS companies, with the underlying assumption that "software revenue is stable and predictable." Once AI makes customers stop renewing, this assumption collapses. And much of this private credit money comes from our pension funds and insurance accounts. Insurance companies face regulatory requirements to recapitalize or sell assets, triggering another market selloff.

The fifth ring is the report's most pessimistic part: this isn't a cycle with natural braking mechanisms. Traditional recessions self-heal—rates drop, construction returns; inventory clears, restocking begins. But AI impact is structural. As AI capabilities continuously improve and costs continuously decline, companies use saved money to buy more AI, causing more layoffs, saving more money, buying more AI. This is a downhill road without brakes.

The report predicts U.S. unemployment touching 10.2% by June 2028, with the S&P 500 significantly retracing from highs. The White House responded calling it "science fiction," mainstream Wall Street firms pointed out this scenario requires five extreme conditions occurring simultaneously, with extremely low probability. But "Black Swan father" Taleb emerged to say: markets underestimate AI risk.

At this point, most people start picking sides—do you find this report credible or alarmist? But I'm more concerned with something else.

One report author, Alap Shah, publicly admitted his strategy is "talk short, go long": shorting companies disrupted by AI while holding beneficiary semiconductor stocks. If his prophecy comes true, he profits directly. This isn't neutral analysis; this is narrative with positions.

This precisely echoes what 2013 Nobel Economics laureate Robert Shiller said. His "narrative economics" points out: narratives precede reality and shape reality. Economic fluctuations aren't driven purely by fundamentals, but by easily transmissible stories. Soros's reflexivity theory says the same thing—participants' beliefs change the observed object itself.

So this report's most alarming aspect isn't whether its five-ring deduction is correct. It's proving one thing: the market's immune system is currently so weak that a thought experiment can trigger systemic reactions. The real risk isn't on AI's capability curve, but in which story the market chooses to believe.

For Taiwan, every link in this chain deserves comparative self-examination. Our semiconductors and hardware manufacturing sit on AI's beneficiary side, but what about our service industries, financial sector, intermediary industries? Taiwan's white-collar density isn't lower than America's, our insurance industry similarly invests heavily in fixed-income products. If the first two links of this chain occur in America, the fourth link's shockwaves won't bypass the Pacific.

Nobody knows if 2028 will become a slaughterhouse. But that Monday, February 23, 2026, already told us one thing:

Markets are never destroyed by facts. They're destroyed by a good enough story.