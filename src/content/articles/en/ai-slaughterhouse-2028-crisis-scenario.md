---
title: "The 2028 Slaughterhouse: An AI Collapse Scenario Keeping Wall Street Awake"
description: "Citrini Research uses a five-ring chain reaction to predict a systemic financial crisis triggered by AI, with Wall Street's volatility merely the prelude."
pillar: ai
tags:
  - AI economic impact
  - financial crisis
  - white-collar unemployment
  - narrative economics
  - Citrini Research
date: 2026-02-27
cover: /images/covers/ai-slaughterhouse-2028-crisis-scenario.jpg
abstract: |
  Citrini Research's "The 2028 Global Intelligence Crisis" report uses a five-ring chain reaction to outline a pathway: AI creates phantom GDP, destroys intermediary business models, triggers white-collar unemployment waves, sparks private credit defaults, ultimately forming a negative feedback loop with no natural braking mechanism. This isn't a prediction—it's a thought experiment. But the market reaction on February 23, 2026, proves that stories themselves are weapons.
thesis: "The real risk of AI collapse lies not in the technical layer, but in the narrative layer—markets only accept one story, and fear always spreads faster than reason."
domain_bridge: "AI systemic risk × narrative economics"
confidence: speculative
content_type: analysis
related_entities:
  - name: Citrini Research
    type: Organization
  - name: James van Guillen
    type: Person
  - name: Robert Shiller
    type: Person
  - name: Nassim Taleb
    type: Person
reading_context: |
  Suitable for investors and industry strategists concerned about AI's macroeconomic impact, as well as readers interested in narrative economics.
---

February 23, 2026, was an unusual Monday on Wall Street. IBM plummeted 13% after Anthropic released COBOL modernization tools, marking its largest single-day drop since 2000; Blackstone fell over 6% due to redemption limits on private credit funds; American Express dropped more than 7%, while the entire software sector declined nearly 5%. Multiple negative factors exploded simultaneously, but the trigger for market sentiment was unexpected—a report from Citrini Research, a small research firm most people had never heard of, using a thought experiment to completely ignite the already inflamed market nerves.

The report's title was provocatively blunt: "The 2028 Global Intelligence Crisis." The Chinese-speaking community was even more direct, with Yu Yingzheng calling it "The 2028 AI Slaughterhouse" in her social media posts.

This is what's unsettling. Not Goldman Sachs, not Morgan Stanley, but a small institution with virtually no brand moat used a thought experiment to move markets. This shows the market's current nerves aren't just tense—they're inflamed, where any stimulus could trigger spasms. Fear doesn't need authoritative endorsement; it only needs a complete enough storyline.

Citrini's storyline is a five-ring chain, each link connecting to the next, forming a path from prosperity to collapse.

The first ring they call "phantom GDP." The logic goes like this: AI enables corporate layoffs, profits soar, productivity hits new highs since the 1950s, and the numbers look beautiful on paper—the S&P 500 approaches 8,000 points, NASDAQ breaks 30,000. But AI only produces; it doesn't consume. It won't buy houses, dine out, or take kids to Disney. Output increases, but labor compensation doesn't flow back to the consumption side. Money velocity slows, the consumer economy contracts. The GDP numbers are real, but the blood circulation supporting them is stagnating.

The second ring is systemic business model collapse. Once AI agents become consumers' omnipotent assistants, all intermediary layers surviving on "human inertia"—price comparison platforms, insurance renewals, travel booking, real estate brokerage—will be penetrated. More lethal is the payment network: when transactions become machine-to-machine, credit cards' 2-3% transaction fees become pure redundant costs. AI agents will automatically switch to zero-cost stablecoin settlements, and Visa and Mastercard's moats are built on these transaction fees.

The third ring is white-collar unemployment triggering consumption collapse. America's structural weakness is exposed here: white-collar workers comprise half of total employment but contribute about 75% of discretionary consumption. After AI replaces white-collar workers, high-skilled laborers flood the gig economy—engineers driving ride-shares, programmers becoming plumbers—depressing everyone's wages. White-collar workers still employed begin precautionary saving, afraid to spend. The consumption engine stalls from both supply and demand sides.

The fourth ring is financial system transmission. In the massive private credit market, substantial funds flow to SaaS companies, with the underlying assumption that "software revenue is stable and predictable." Once AI makes clients stop renewing subscriptions, this assumption collapses. Much of this private credit money comes from our pension funds and insurance accounts. Insurance companies are required by regulation to recapitalize or sell assets, triggering another stock market decline.

The fifth ring is the report's most pessimistic part: this isn't a cycle with natural braking mechanisms. Traditional recessions self-repair—when interest rates drop, construction returns; when inventory clears, restocking begins. But AI impact is structural. AI capabilities continue improving, costs continue falling, companies use saved money to buy more AI, leading to more layoffs, saving more money, buying more AI. This is a downhill road without brakes.

The report predicts US unemployment will reach 10.2% in June 2028, with the S&P 500 significantly retreating from its peak. The White House's response was "science fiction," mainstream Wall Street institutions pointed out this scenario requires five extreme conditions to occur simultaneously, with extremely low probability. But "Black Swan father" Taleb came out saying: markets underestimate AI risks.

At this point, most people would start taking sides—do you find this report credible or alarmist? But I'm more concerned about something else.

Report co-author Alap Shah publicly admits his strategy is "talk down, buy up": shorting companies disrupted by AI while holding beneficial semiconductor stocks. If his prophecy comes true, he profits directly. This isn't neutral analysis; this is narrative with positions.

This is precisely what 2013 Nobel Economics Prize winner Robert Shiller discussed. His "narrative economics" points out: narratives precede reality and shape reality. Economic fluctuations aren't purely driven by fundamentals; they're driven by easily transmissible stories. Soros's reflexivity theory says the same thing—participants' beliefs change the observed object itself.

So this report's most alarming aspect isn't whether its five-ring deduction is correct. It's that it proves one thing: the market's immune system is currently so weak that a thought experiment can trigger systemic reactions. The real risk isn't on AI's capability curve; it's in which story the market chooses to believe.

For Taiwan, every link in this chain deserves self-examination. Our semiconductors and hardware manufacturing sit on AI's beneficiary side, but what about our service industries, financial sector, intermediary industries? Taiwan's white-collar density is no lower than America's, our insurance industry similarly invests heavily in fixed-income products. If the first two rings of this chain occur in America, the fourth ring's shockwaves won't bypass the Pacific.

No one knows if 2028 will become a slaughterhouse. But that Monday, February 23, 2026, already told us one thing:

Markets are never crushed by facts. They're crushed by a good enough story.