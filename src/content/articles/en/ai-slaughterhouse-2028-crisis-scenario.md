---
title: "Slaughterhouse 2028: An AI Collapse Scenario That Kept Wall Street Awake"
description: "Citrini Research uses five-link chain analysis to predict systemic financial crisis triggered by AI—Wall Street turbulence is just the prelude."
pillar: ai
tags:
  - AI經濟衝擊
  - 金融危機
  - 白領失業
  - 敘事經濟學
  - Citrini Research
date: 2026-02-27
cover: /images/covers/ai-slaughterhouse-2028-crisis-scenario.jpg
abstract: |
  Citrini Research's "2028 Global Intelligence Crisis" report uses five-link chain analysis to map a pathway: AI creates phantom GDP, destroys intermediary business models, triggers white-collar unemployment waves, sparks private credit defaults, ultimately forming negative feedback loops without natural braking mechanisms. This isn't prediction—it's a thought experiment. But the market reaction on February 23, 2026 proved that narratives themselves are weapons.
thesis: "The real risk of AI collapse lies not in the technical layer but in the narrative layer—markets only accept one story, and fear always spreads faster than reason."
domain_bridge: "AI Systemic Risk × Narrative Economics"
confidence: speculative
content_type: analysis
related_entities:
  - name: Citrini Research
    type: Organization
  - name: 詹姆斯·范·吉倫
    type: Person
  - name: 羅伯特·希勒
    type: Person
  - name: 納西姆·塔勒布
    type: Person
reading_context: |
  Suitable for investors, industry strategists concerned with AI's macroeconomic impact, and readers interested in narrative economics.
---

February 23, 2026, Wall Street weathered an unusual Monday. IBM plummeted 13% after Anthropic released COBOL modernization tools, marking its largest single-day drop since 2000; Blackstone fell over 6% under private credit fund redemption restrictions; American Express dropped over 7%, with the software sector declining nearly 5% overall. Multiple bearish factors ignited simultaneously, but the market sentiment's fuse was unexpected—a report from Citrini Research, a small investment research firm most had never heard of, used a thought experiment to completely ignite already inflamed market nerves.

The report's title was blunt to the point of provocation: [*The 2028 Global Intelligence Crisis*](https://www.citriniresearch.com/p/2028gic). Chinese circles were even more direct, with Yu Yingzheng calling it "The 2028 AI Slaughterhouse" in social media posts.

This is what's unsettling. Not Goldman Sachs, not Morgan Stanley, but a small firm with virtually no brand moat used a thought experiment to move markets. This shows the market's nerves aren't just taut—they're inflamed, where any stimulus could trigger spasms. Fear needs no authoritative endorsement, only a sufficiently complete storyline.

Citrini's storyline is a five-link chain, each link gripping the next, forming a pathway from prosperity to collapse.

The first link they call "phantom GDP." The logic goes like this: AI enables corporate layoffs, profits soar, productivity hits new highs since the 1950s, and the numbers look beautiful on paper—the S&P 500 approaching 8,000, NASDAQ breaking 30,000. But AI only produces, never consumes. It won't buy houses, dine out, or take kids to Disney. Output increases, but labor compensation doesn't flow back to the consumption side. Money's velocity slows, the consumer economy shrinks. GDP numbers are real, but the circulatory system supporting them has already stagnated.

The second link is systematic collapse of business models. Once AI agents become consumers' omnipotent assistants, all intermediary layers surviving on "human inertia"—price comparison platforms, insurance renewals, travel bookings, real estate brokers—will be penetrated. More lethal is the payments network: when transactions become machine-to-machine, credit cards' 2-3% fees become pure redundant costs. AI agents will automatically switch to zero-cost stablecoin settlement, and Visa and Mastercard's moats are built precisely on these fee layers.

The third link is white-collar unemployment triggering consumption collapse. America's structural weakness is exposed here: white-collar workers comprise half of total employment but contribute roughly 75% of discretionary consumption. After AI replaces white-collar workers, high-skilled labor floods the gig economy—engineers driving Uber, programmers doing plumbing—depressing everyone's wages. Remaining white-collar workers begin precautionary saving, afraid to spend. The consumption engine stalls from both supply and demand sides.

The fourth link is financial system transmission. In the massive private credit market, substantial funds flow to SaaS companies under the assumption that "software revenue is stable and predictable." Once AI causes customers to stop renewing, this assumption collapses. Much of this private credit money comes from our pension and insurance accounts. Insurance companies face regulatory requirements to recapitalize or sell assets, causing another market decline.

The fifth link is the report's most pessimistic part: this isn't a cycle with natural braking mechanisms. Traditional recessions self-repair—when rates fall, construction returns; when inventory clears, restocking begins. But AI impact is structural. As AI capabilities continuously improve and costs continuously decline, companies use savings to buy more AI, causing more layoffs, saving more money, buying more AI. This is a downhill road without brakes.

The report predicts U.S. unemployment will touch 10.2% in June 2028, with the S&P 500 retreating significantly from its peak. The White House responds with "science fiction," mainstream Wall Street firms point out this scenario requires five extreme conditions to occur simultaneously—extremely low probability. But "Black Swan" father Nassim Taleb says one thing: markets underestimate AI's risks.

Here, most people would start choosing sides—do you find this report credible or alarmist? But I'm more concerned with something else.

Report co-author Alap Shah openly admits his strategy is "short the story, long the trend": shorting companies disrupted by AI while holding beneficiary semiconductor stocks. If his prophecy comes true, he profits directly. This isn't neutral analysis—this is narrative with positions.

And this is precisely what 2013 Nobel Economics laureate Robert Shiller described. His "narrative economics" indicates: narratives precede reality and shape reality. Economic fluctuations aren't driven purely by fundamentals—they're driven by easily transmissible stories. George Soros's reflexivity theory says the same thing—participants' beliefs change the observed object itself.

So this report's most alarming aspect isn't whether its five-link analysis is correct. It's that it proves one thing: the market's immune system is now so weak that a thought experiment can trigger systemic reactions. The real risk isn't on AI's capability curve—it's in which story markets choose to believe.

For Taiwan, every link in this chain deserves comparative self-examination. Our semiconductors and hardware manufacturing sit on AI's beneficiary side, but what about our service industries, financial sector, intermediary industries? Taiwan's white-collar density is no lower than America's, our insurance industry similarly invests heavily in fixed-income products. If the first two links of this chain occur in America, the fourth link's shockwaves won't bypass the Pacific.

No one knows if 2028 will become a slaughterhouse. But that Monday, February 23, 2026, already told us one thing:

Markets are never crushed by facts. They're crushed by a good enough story.

---

**References**

Citrini Research & Alap Shah, *The 2028 Global Intelligence Crisis*, February 22, 2026. [Original Link](https://www.citriniresearch.com/p/2028gic)